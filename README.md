#训练：
#数据准备：将训练集数据按照每个epoch随机打乱，以确保模型在每个epoch中看到的数据顺序不同。同时，将验证集数据保持不变，用于评估模型在未见过的数据上的性能。
#迭代训练：在每个epoch中，将训练集数据按照指定的批量大小分成多个小批量，并通过模型的前向传播计算损失，并通过反向传播更新模型参数。
#计算指标：在每个epoch结束后，使用更新后的模型在验证集上进行前向传播，计算验证集上的损失和准确率，以监控模型的训练情况和泛化能力。
#保存最佳模型：在每个epoch中，如果当前的验证损失低于之前的最低验证损失，则保存当前模型参数为最佳模型参数。这样做的目的是在训练过程中迭代选择出在验证集上表现最好的模型。
#测试：
#超参数组合的搜索：通过嵌套的循环，遍历了指定的超参数组合空间。其中，hidden_sizes定义了隐藏层大小的候选值，learning_rates定义了学习率的候选值，l2_lambdas定义了L2正则化参数的候选值。
#模型训练与验证：对于每一组超参数组合，创建一个新的神经网络模型，并使用训练集和验证集进行模型训练和验证。在训练过程中，使用了之前定义的训练函数train_model，对模型进行了10个epoch的训练，并在每个epoch结束后记录了训练损失、验证损失和验证准确率。
#选择最佳模型：在每次验证结束后，根据当前模型在验证集上的准确率，更新记录的最佳验证准确率、最佳模型和对应的超参数组合。如果当前模型的验证准确率高于之前的最佳准确率，则更新最佳模型及其对应的超参数。
#结果展示：在所有超参数组合遍历完成后，输出最佳超参数组合及对应的最佳模型。这些最佳超参数可以作为进一步训练模型或在测试集上评估模型时的参考。
